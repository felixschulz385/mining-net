{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae232a31",
   "metadata": {},
   "source": [
    "# Convert Mining Dataset to Zarr Format and Benchmark\n",
    "\n",
    "This notebook converts the existing memory-mapped `.npy` tile structure to uncompressed Zarr format with optimized chunking, then benchmarks data loading performance.\n",
    "\n",
    "## Objectives\n",
    "1. Convert existing data structure (manifests + .npy files) to Zarr\n",
    "2. Use chunk size of 8 tiles for optimal I/O performance\n",
    "3. Benchmark data loading speed: old design vs. Zarr\n",
    "4. Analyze memory usage and I/O patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "128c7a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zarr version: 3.1.5\n",
      "NumPy version: 2.3.5\n",
      "PyTorch version: 2.10.0+cu130\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import time\n",
    "import numpy as np\n",
    "import zarr\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Add src to path\n",
    "sys.path.insert(0, str(Path.cwd().parent))\n",
    "\n",
    "from config import Config\n",
    "from manifest_reader import ManifestReader\n",
    "from network.data_loader import MiningSegmentationDataLoader\n",
    "\n",
    "print(f\"Zarr version: {zarr.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b04121",
   "metadata": {},
   "source": [
    "## 1. Setup and Explore Current Data Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c587367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manifests directory: /scicore/home/meiera/schulz0022/projects/mining-net/data/manifests\n",
      "MMAP directory: /scicore/home/meiera/schulz0022/projects/mining-net/data/landsat_mmap\n",
      "Zarr output directory: /scicore/home/meiera/schulz0022/projects/mining-net/data/landsat_zarr\n",
      "\n",
      "Manifests exist: True\n",
      "MMAP data exist: True\n"
     ]
    }
   ],
   "source": [
    "# Initialize config and manifest reader\n",
    "config = Config()\n",
    "manifests_dir = config.DATA_DIR / \"manifests\"\n",
    "mmap_dir = config.MMAP_DIR\n",
    "zarr_dir = config.DATA_DIR / \"landsat_zarr\"\n",
    "\n",
    "print(f\"Manifests directory: {manifests_dir}\")\n",
    "print(f\"MMAP directory: {mmap_dir}\")\n",
    "print(f\"Zarr output directory: {zarr_dir}\")\n",
    "print(f\"\\nManifests exist: {manifests_dir.exists()}\")\n",
    "print(f\"MMAP data exist: {mmap_dir.exists()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c4160897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 227 clusters\n",
      "\n",
      "Sample clusters:\n",
      "  Cluster 6155687546600015 (ZAF) -   72 tiles, years [2019]\n",
      "  Cluster 16714675725600725 (ZAF) -  169 tiles, years [2019]\n",
      "  Cluster 17315396644879081 (ZAF) -  110 tiles, years [2019]\n",
      "  Cluster 52652953960301590 (ZAF) -  100 tiles, years [2019]\n",
      "  Cluster 62084203559214856 (ZAF) -   63 tiles, years [2019]\n",
      "  ... and 222 more clusters\n"
     ]
    }
   ],
   "source": [
    "# Explore available data using manifest reader\n",
    "reader = ManifestReader(manifests_dir)\n",
    "all_manifests = reader.list_all_manifests()\n",
    "\n",
    "print(f\"Found {len(all_manifests)} clusters\\n\")\n",
    "print(\"Sample clusters:\")\n",
    "for manifest in all_manifests[:5]:\n",
    "    print(f\"  Cluster {manifest['cluster_id']:>10} ({manifest['country_code']}) - \"\n",
    "          f\"{manifest['tile_count']:>4} tiles, years {manifest['years']}\")\n",
    "\n",
    "if len(all_manifests) > 5:\n",
    "    print(f\"  ... and {len(all_manifests) - 5} more clusters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff302b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tiles: 43,023\n",
      "Countries: ['ZAF']\n",
      "Years: [2019]\n",
      "\n",
      "Estimated data size (assuming 256x256 tiles, 7 bands + 1 label):\n",
      "  ~84.03 GB\n"
     ]
    }
   ],
   "source": [
    "# Get total tile count and data statistics\n",
    "total_tiles = sum(m['tile_count'] for m in all_manifests)\n",
    "countries = set(m['country_code'] for m in all_manifests)\n",
    "all_years = set()\n",
    "for m in all_manifests:\n",
    "    all_years.update(m['years'])\n",
    "\n",
    "print(f\"Total tiles: {total_tiles:,}\")\n",
    "print(f\"Countries: {sorted(countries)}\")\n",
    "print(f\"Years: {sorted(all_years)}\")\n",
    "print(f\"\\nEstimated data size (assuming 256x256 tiles, 7 bands + 1 label):\")\n",
    "tile_size = 256 * 256 * 8 * 4  # 8 channels, 4 bytes per float32\n",
    "total_size_gb = (total_tiles * tile_size) / (1024**3)\n",
    "print(f\"  ~{total_size_gb:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31bea3b",
   "metadata": {},
   "source": [
    "## 2. Inspect a Sample Tile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f857d89d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample tile metadata:\n",
      "  Cluster: 6155687546600015\n",
      "  Country: ZAF\n",
      "  Year: 2019\n",
      "  Tile indices: (6841, 11646)\n",
      "\n",
      "Tile path: /scicore/home/meiera/schulz0022/projects/mining-net/data/landsat_mmap/6155687546600015/2019/6841_11646\n",
      "Exists: True\n",
      "\n",
      "Features shape: (7, 64, 64)\n",
      "Features dtype: float32\n",
      "Labels shape: (1, 64, 64)\n",
      "Labels dtype: float32\n",
      "\n",
      "Features range: [0.0514, 316.3787]\n",
      "Labels unique values: [0.]\n"
     ]
    }
   ],
   "source": [
    "# Load a sample tile to understand data structure\n",
    "sample_manifest = reader.read_manifest(all_manifests[0]['cluster_id'])\n",
    "sample_tile = sample_manifest['tiles'][0]\n",
    "\n",
    "print(\"Sample tile metadata:\")\n",
    "print(f\"  Cluster: {sample_manifest['cluster_id']}\")\n",
    "print(f\"  Country: {sample_manifest['country_code']}\")\n",
    "print(f\"  Year: {sample_tile['year']}\")\n",
    "print(f\"  Tile indices: ({sample_tile['tile_ix']}, {sample_tile['tile_iy']})\")\n",
    "\n",
    "# Load the actual data\n",
    "tile_path = mmap_dir / str(sample_manifest['cluster_id']) / str(sample_tile['year']) / f\"{sample_tile['tile_ix']}_{sample_tile['tile_iy']}\"\n",
    "print(f\"\\nTile path: {tile_path}\")\n",
    "print(f\"Exists: {tile_path.exists()}\")\n",
    "\n",
    "if tile_path.exists():\n",
    "    features = np.load(tile_path / \"features.npy\", mmap_mode='r')\n",
    "    labels = np.load(tile_path / \"labels.npy\", mmap_mode='r')\n",
    "    \n",
    "    print(f\"\\nFeatures shape: {features.shape}\")\n",
    "    print(f\"Features dtype: {features.dtype}\")\n",
    "    print(f\"Labels shape: {labels.shape}\")\n",
    "    print(f\"Labels dtype: {labels.dtype}\")\n",
    "    print(f\"\\nFeatures range: [{features.min():.4f}, {features.max():.4f}]\")\n",
    "    print(f\"Labels unique values: {np.unique(labels)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a77182",
   "metadata": {},
   "source": [
    "## 3. Design Zarr Structure\n",
    "\n",
    "We'll create a single Zarr group with multiple arrays:\n",
    "```\n",
    "landsat_zarr/\n",
    "└── data.zarr/           # Zarr group containing:\n",
    "    ├── features         # Shape: (N_tiles, C, H, W), chunks: (8, C, H, W)\n",
    "    ├── labels           # Shape: (N_tiles, 1, H, W), chunks: (8, 1, H, W)\n",
    "    ├── cluster_ids      # Shape: (N_tiles,) - cluster ID for each tile\n",
    "    ├── tile_ix          # Shape: (N_tiles,) - tile X index\n",
    "    ├── tile_iy          # Shape: (N_tiles,) - tile Y index\n",
    "    └── years            # Shape: (N_tiles,) - year for each tile\n",
    "```\n",
    "\n",
    "Benefits:\n",
    "- Single unified Zarr group for all data\n",
    "- Chunk size of 8 tiles optimizes for batch loading\n",
    "- Index arrays enable efficient filtering and queries\n",
    "- Uncompressed for maximum read speed\n",
    "- Scalable structure for cloud storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f5eb1bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created Zarr directory: /scicore/home/meiera/schulz0022/projects/mining-net/data/landsat_zarr\n"
     ]
    }
   ],
   "source": [
    "# Create Zarr directory structure\n",
    "zarr_dir.mkdir(parents=True, exist_ok=True)\n",
    "(zarr_dir / \"metadata\").mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"Created Zarr directory: {zarr_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c61b7fd",
   "metadata": {},
   "source": [
    "## 4. Convert Data to Zarr Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b0b10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_zarr(\n",
    "    manifests_dir: Path,\n",
    "    mmap_dir: Path,\n",
    "    zarr_dir: Path,\n",
    "    chunk_size: int = 8,\n",
    "    max_tiles: int = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Convert memory-mapped tile structure to Zarr format with index arrays.\n",
    "    \n",
    "    Args:\n",
    "        manifests_dir: Directory with manifest files\n",
    "        mmap_dir: Directory with .npy tiles\n",
    "        zarr_dir: Output directory for Zarr group\n",
    "        chunk_size: Number of tiles per chunk\n",
    "        max_tiles: Maximum tiles to convert (for testing)\n",
    "    \"\"\"\n",
    "    import json\n",
    "    \n",
    "    reader = ManifestReader(manifests_dir)\n",
    "    all_manifests = reader.list_all_manifests()\n",
    "    \n",
    "    # Build complete tile index\n",
    "    print(\"Building tile index...\")\n",
    "    tile_index = []\n",
    "    \n",
    "    for manifest_meta in tqdm(all_manifests, desc=\"Reading manifests\"):\n",
    "        manifest = reader.read_manifest(manifest_meta['cluster_id'])\n",
    "        if not manifest:\n",
    "            continue\n",
    "        \n",
    "        for tile in manifest['tiles']:\n",
    "            tile_index.append({\n",
    "                'cluster_id': manifest['cluster_id'],\n",
    "                'country_code': manifest['country_code'],\n",
    "                'year': tile['year'],\n",
    "                'tile_ix': tile['tile_ix'],\n",
    "                'tile_iy': tile['tile_iy'],\n",
    "                'geometry_hash': tile.get('geometry_hash'),\n",
    "            })\n",
    "            \n",
    "            if max_tiles and len(tile_index) >= max_tiles:\n",
    "                break\n",
    "        \n",
    "        if max_tiles and len(tile_index) >= max_tiles:\n",
    "            break\n",
    "    \n",
    "    n_tiles = len(tile_index)\n",
    "    print(f\"Found {n_tiles:,} tiles to convert\")\n",
    "    \n",
    "    # Load first tile to get dimensions\n",
    "    first_tile = tile_index[0]\n",
    "    tile_path = mmap_dir / str(first_tile['cluster_id']) / str(first_tile['year']) / f\"{first_tile['tile_ix']}_{first_tile['tile_iy']}\"\n",
    "    sample_features = np.load(tile_path / \"features.npy\", mmap_mode='r')\n",
    "    sample_labels = np.load(tile_path / \"labels.npy\", mmap_mode='r')\n",
    "    \n",
    "    n_channels, height, width = sample_features.shape\n",
    "    print(f\"Tile dimensions: {n_channels} channels, {height}x{width} pixels\")\n",
    "    \n",
    "    # Create Zarr group with all arrays\n",
    "    print(f\"\\nCreating Zarr group (chunk size: {chunk_size} tiles)...\")\n",
    "    \n",
    "    group_path = zarr_dir / \"data.zarr\"\n",
    "    zarr_group = zarr.open_group(store=str(group_path), mode='w')\n",
    "    \n",
    "    # Create data arrays\n",
    "    features_store = zarr_group.create_array(\n",
    "        'features',\n",
    "        shape=(n_tiles, n_channels, height, width),\n",
    "        chunks=(chunk_size, n_channels, height, width),\n",
    "        dtype=np.float32,\n",
    "        compressors=zarr.codecs.BloscCodec(cname='zstd', clevel=0, shuffle=\"shuffle\", blocksize=0),\n",
    "    )\n",
    "    \n",
    "    labels_store = zarr_group.create_array(\n",
    "        'labels',\n",
    "        shape=(n_tiles, 1, height, width),\n",
    "        chunks=(chunk_size, 1, height, width),\n",
    "        dtype=np.float32,\n",
    "        compressors=zarr.codecs.BloscCodec(cname='zstd', clevel=0, shuffle=\"shuffle\", blocksize=0),\n",
    "    )\n",
    "    \n",
    "    # Create index arrays\n",
    "    index_chunk = chunk_size * 1000  # Larger chunks for 1D index arrays\n",
    "    \n",
    "    cluster_ids_store = zarr_group.create_array(\n",
    "        'cluster_ids',\n",
    "        shape=(n_tiles,),\n",
    "        chunks=(index_chunk,),\n",
    "        dtype=np.int64,\n",
    "        compressors=zarr.codecs.BloscCodec(cname='zstd', clevel=0, shuffle=\"shuffle\", blocksize=0),\n",
    "    )\n",
    "    \n",
    "    tile_ix_store = zarr_group.create_array(\n",
    "        'tile_ix',\n",
    "        shape=(n_tiles,),\n",
    "        chunks=(index_chunk,),\n",
    "        dtype=np.int32,\n",
    "        compressors=zarr.codecs.BloscCodec(cname='zstd', clevel=0, shuffle=\"shuffle\", blocksize=0),\n",
    "    )\n",
    "    \n",
    "    tile_iy_store = zarr_group.create_array(\n",
    "        'tile_iy',\n",
    "        shape=(n_tiles,),\n",
    "        chunks=(index_chunk,),\n",
    "        dtype=np.int32,\n",
    "        compressors=zarr.codecs.BloscCodec(cname='zstd', clevel=0, shuffle=\"shuffle\", blocksize=0),\n",
    "    )\n",
    "    \n",
    "    years_store = zarr_group.create_array(\n",
    "        'years',\n",
    "        shape=(n_tiles,),\n",
    "        chunks=(index_chunk,),\n",
    "        dtype=np.int32,\n",
    "        compressors=zarr.codecs.BloscCodec(cname='zstd', clevel=0, shuffle=\"shuffle\", blocksize=0),\n",
    "    )\n",
    "    \n",
    "    print(f\"Features array: shape={features_store.shape}, chunks={features_store.chunks}\")\n",
    "    print(f\"Labels array: shape={labels_store.shape}, chunks={labels_store.chunks}\")\n",
    "    print(f\"Index arrays: shape=({n_tiles},), chunks=({index_chunk},)\")\n",
    "    \n",
    "    # Copy data tile by tile\n",
    "    print(\"\\nCopying tiles...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for idx, tile_meta in enumerate(tqdm(tile_index, desc=\"Converting tiles\")):\n",
    "        tile_path = mmap_dir / str(tile_meta['cluster_id']) / str(tile_meta['year']) / f\"{tile_meta['tile_ix']}_{tile_meta['tile_iy']}\"\n",
    "        \n",
    "        try:\n",
    "            features = np.load(tile_path / \"features.npy\", mmap_mode='r')\n",
    "            labels = np.load(tile_path / \"labels.npy\", mmap_mode='r')\n",
    "            \n",
    "            features_store[idx] = features\n",
    "            labels_store[idx] = labels\n",
    "            \n",
    "            # Store index data\n",
    "            cluster_ids_store[idx] = tile_meta['cluster_id']\n",
    "            tile_ix_store[idx] = tile_meta['tile_ix']\n",
    "            tile_iy_store[idx] = tile_meta['tile_iy']\n",
    "            years_store[idx] = tile_meta['year']\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\nError loading tile {idx}: {e}\")\n",
    "            # Fill with zeros on error\n",
    "            features_store[idx] = np.zeros((n_channels, height, width), dtype=np.float32)\n",
    "            labels_store[idx] = np.zeros((1, height, width), dtype=np.float32)\n",
    "            cluster_ids_store[idx] = 0\n",
    "            tile_ix_store[idx] = 0\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\nError loading tile {idx}: {e}\")\n",
    "            # Fill with zeros on error\n",
    "            features_store[idx] = np.zeros((n_channels, height, width), dtype=np.float32)\n",
    "            labels_store[idx] = np.zeros((1, height, width), dtype=np.float32)\n",
    "            cluster_ids_store[idx] = 0\n",
    "            tile_ix_store[idx] = 0\n",
    "            tile_iy_store[idx] = 0\n",
    "            years_store[idx] = 0\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"\\nConversion complete in {elapsed:.2f}s ({n_tiles/elapsed:.1f} tiles/s)\")\n",
    "    \n",
    "    # Save tile index as JSON for backward compatibility\n",
    "    metadata_path = zarr_dir / \"metadata\" / \"tiles.json\"\n",
    "    metadata_path.parent.mkdir(exist_ok=True)\n",
    "    with open(metadata_path, 'w') as f:\n",
    "        json.dump(tile_index, f, indent=2)\n",
    "        print(f\"Saved metadata: {metadata_path}\")        # Print storage info    zarr_size = sum(f.stat().st_size for f in zarr_dir.rglob('*') if f.is_file())    zarr_size_gb = zarr_size / (1024**3)    print(f\"\\nTotal Zarr size: {zarr_size_gb:.2f} GB\")        return tile_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c984d960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building tile index...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d0ca85ea38049258b14f8c9d446b0f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Reading manifests:   0%|          | 0/227 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1,000 tiles to convert\n",
      "Tile dimensions: 7 channels, 64x64 pixels\n",
      "\n",
      "Creating Zarr group (chunk size: 8 tiles)...\n",
      "Features array: shape=(1000, 7, 64, 64), chunks=(8, 7, 64, 64)\n",
      "Labels array: shape=(1000, 1, 64, 64), chunks=(8, 1, 64, 64)\n",
      "Index arrays: shape=(1000,), chunks=(8000,)\n",
      "\n",
      "Copying tiles...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2db57cafc61948f88c5ed7320a42e191",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Converting tiles:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Conversion complete in 51.05s (19.6 tiles/s)\n",
      "Saved metadata: /scicore/home/meiera/schulz0022/projects/mining-net/data/landsat_zarr/metadata/tiles.json\n"
     ]
    }
   ],
   "source": [
    "# Convert a subset for testing (set max_tiles=None to convert all)\n",
    "tile_index = convert_to_zarr(\n",
    "    manifests_dir=manifests_dir,\n",
    "    mmap_dir=mmap_dir,\n",
    "    zarr_dir=zarr_dir,\n",
    "    chunk_size=8,\n",
    "    max_tiles=1000  # Start with 1000 tiles for testing\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6ac790f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying converted Zarr group...\n",
      "\n",
      "Zarr group arrays:\n",
      "\n",
      "tile_ix:\n",
      "  Shape: (1000,)\n",
      "  Chunks: (8000,)\n",
      "  Dtype: int32\n",
      "\n",
      "years:\n",
      "  Shape: (1000,)\n",
      "  Chunks: (8000,)\n",
      "  Dtype: int32\n",
      "\n",
      "features:\n",
      "  Shape: (1000, 7, 64, 64)\n",
      "  Chunks: (8, 7, 64, 64)\n",
      "  Dtype: float32\n",
      "  Size: 0.11 GB\n",
      "\n",
      "labels:\n",
      "  Shape: (1000, 1, 64, 64)\n",
      "  Chunks: (8, 1, 64, 64)\n",
      "  Dtype: float32\n",
      "  Size: 0.02 GB\n",
      "\n",
      "tile_iy:\n",
      "  Shape: (1000,)\n",
      "  Chunks: (8000,)\n",
      "  Dtype: int32\n",
      "\n",
      "cluster_ids:\n",
      "  Shape: (1000,)\n",
      "  Chunks: (8000,)\n",
      "  Dtype: int64\n",
      "\n",
      "Verifying data access...\n",
      "  Sample features: (7, 64, 64), range=[0.0514, 316.3787]\n",
      "  Sample labels: (1, 64, 64), unique values=[0.]\n",
      "\n",
      "  Sample indices:\n",
      "    cluster_id: 6155687546600015\n",
      "    tile_ix: 6841\n",
      "    tile_iy: 11646\n",
      "    year: 2019\n",
      "\n",
      "✓ Zarr conversion verified successfully!\n"
     ]
    }
   ],
   "source": [
    "# Verify the conversion\n",
    "print(\"Verifying converted Zarr group...\")\n",
    "\n",
    "zarr_group = zarr.open_group(store=str(zarr_dir / \"data.zarr\"), mode='r')\n",
    "\n",
    "print(f\"\\nZarr group arrays:\")\n",
    "for name in zarr_group.array_keys():\n",
    "    array = zarr_group[name]\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  Shape: {array.shape}\")\n",
    "    print(f\"  Chunks: {array.chunks}\")\n",
    "    print(f\"  Dtype: {array.dtype}\")\n",
    "    if len(array.shape) > 1:  # Data arrays\n",
    "        print(f\"  Size: {array.nbytes / (1024**3):.2f} GB\")\n",
    "\n",
    "# Verify we can read data\n",
    "print(\"\\nVerifying data access...\")\n",
    "sample_features = zarr_group['features'][0]\n",
    "sample_labels = zarr_group['labels'][0]\n",
    "print(f\"  Sample features: {sample_features.shape}, range=[{sample_features.min():.4f}, {sample_features.max():.4f}]\")\n",
    "print(f\"  Sample labels: {sample_labels.shape}, unique values={np.unique(sample_labels)}\")\n",
    "\n",
    "# Verify index arrays\n",
    "print(f\"\\n  Sample indices:\")\n",
    "print(f\"    cluster_id: {zarr_group['cluster_ids'][0]}\")\n",
    "print(f\"    tile_ix: {zarr_group['tile_ix'][0]}\")\n",
    "print(f\"    tile_iy: {zarr_group['tile_iy'][0]}\")\n",
    "print(f\"    year: {zarr_group['years'][0]}\")\n",
    "\n",
    "print(\"\\n✓ Zarr conversion verified successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fb12f274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying index arrays...\n",
      "\n",
      "Available arrays:\n",
      "  labels: shape=(1000, 1, 64, 64), dtype=float32\n",
      "  tile_ix: shape=(1000,), dtype=int32\n",
      "  cluster_ids: shape=(1000,), dtype=int64\n",
      "  tile_iy: shape=(1000,), dtype=int32\n",
      "  features: shape=(1000, 7, 64, 64), dtype=float32\n",
      "  years: shape=(1000,), dtype=int32\n",
      "\n",
      "Sample data (first 5 tiles):\n",
      "  cluster_ids: [6155687546600015 6155687546600015 6155687546600015 6155687546600015\n",
      " 6155687546600015]\n",
      "  tile_ix: [6841 6841 6841 6841 6841]\n",
      "  tile_iy: [11646 11647 11648 11649 11650]\n",
      "  years: [2019 2019 2019 2019 2019]\n",
      "\n",
      "Example query: Cluster 6155687546600015 has 72 tiles\n",
      "\n",
      "✓ Index arrays are working correctly!\n"
     ]
    }
   ],
   "source": [
    "# Verify the index arrays\n",
    "print(\"Verifying index arrays...\")\n",
    "\n",
    "zarr_group = zarr.open_group(store=str(zarr_dir / \"data.zarr\"), mode='r')\n",
    "\n",
    "print(f\"\\nAvailable arrays:\")\n",
    "for name in zarr_group.array_keys():\n",
    "    array = zarr_group[name]\n",
    "    print(f\"  {name}: shape={array.shape}, dtype={array.dtype}\")\n",
    "\n",
    "# Test accessing with indices\n",
    "if 'cluster_ids' in zarr_group:\n",
    "    print(f\"\\nSample data (first 5 tiles):\")\n",
    "    print(f\"  cluster_ids: {zarr_group['cluster_ids'][:5]}\")\n",
    "    print(f\"  tile_ix: {zarr_group['tile_ix'][:5]}\")\n",
    "    print(f\"  tile_iy: {zarr_group['tile_iy'][:5]}\")\n",
    "    print(f\"  years: {zarr_group['years'][:5]}\")\n",
    "    \n",
    "    # Example: Find all tiles for a specific cluster\n",
    "    cluster_id = zarr_group['cluster_ids'][0]\n",
    "    mask = zarr_group['cluster_ids'][:] == cluster_id\n",
    "    n_tiles_in_cluster = mask.sum()\n",
    "    print(f\"\\nExample query: Cluster {cluster_id} has {n_tiles_in_cluster} tiles\")\n",
    "    \n",
    "    print(\"\\n✓ Index arrays are working correctly!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980d8d11",
   "metadata": {},
   "source": [
    "## 4.2 Convert Entire Dataset to Zarr\n",
    "\n",
    "Now let's convert the full dataset (not just a subset for testing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93138dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting full dataset conversion to Zarr...\n",
      "======================================================================\n",
      "Building tile index...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d30e945191bb447bae06a2c327a18842",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Reading manifests:   0%|          | 0/227 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 43,023 tiles to convert\n",
      "Tile dimensions: 7 channels, 64x64 pixels\n",
      "\n",
      "Creating Zarr group (chunk size: 8 tiles)...\n",
      "Features array: shape=(43023, 7, 64, 64), chunks=(8, 7, 64, 64)\n",
      "Labels array: shape=(43023, 1, 64, 64), chunks=(8, 1, 64, 64)\n",
      "Index arrays: shape=(43023,), chunks=(8000,)\n",
      "\n",
      "Copying tiles...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c597d9cdb0344e3bb7ee75a486317321",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Converting tiles:   0%|          | 0/43023 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert the entire dataset\n",
    "# WARNING: This will take significant time depending on dataset size\n",
    "# Set max_tiles=None to convert ALL tiles\n",
    "print(\"Starting full dataset conversion to Zarr...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "full_tile_index = convert_to_zarr(\n",
    "    manifests_dir=manifests_dir,\n",
    "    mmap_dir=mmap_dir,\n",
    "    zarr_dir=zarr_dir,\n",
    "    chunk_size=8,\n",
    "    max_tiles=None  # Convert ALL tiles\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(f\"✓ Full conversion complete: {len(full_tile_index):,} tiles\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8453d472",
   "metadata": {},
   "source": [
    "## 5. Implement Zarr-based DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff5ca88",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZarrMiningDataLoader(Dataset):\n",
    "    \"\"\"\n",
    "    PyTorch Dataset for mining segmentation using Zarr backend.\n",
    "    \n",
    "    Optimized for batch loading with chunked Zarr arrays.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        zarr_dir: Path,\n",
    "        normalize: bool = True,\n",
    "        band_means: list = None,\n",
    "        band_stds: list = None,\n",
    "        cluster_filter: list = None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize Zarr-based data loader.\n",
    "        \n",
    "        Args:\n",
    "            zarr_dir: Directory containing Zarr group\n",
    "            normalize: Whether to normalize inputs\n",
    "            band_means: Precomputed band means\n",
    "            band_stds: Precomputed band stds\n",
    "            cluster_filter: Optional list of cluster IDs to include\n",
    "        \"\"\"\n",
    "        self.zarr_dir = Path(zarr_dir)\n",
    "        \n",
    "        # Open Zarr group (lazy, no data loaded yet)\n",
    "        self.zarr_group = zarr.open_group(store=str(self.zarr_dir / \"data.zarr\"), mode='r')\n",
    "        \n",
    "        self.features = self.zarr_group['features']\n",
    "        self.labels = self.zarr_group['labels']\n",
    "        \n",
    "        # Apply cluster filter if provided\n",
    "        if cluster_filter is not None:\n",
    "            cluster_ids = self.zarr_group['cluster_ids'][:]\n",
    "            self.valid_indices = np.where(np.isin(cluster_ids, cluster_filter))[0]\n",
    "            print(f\"Filtered to {len(self.valid_indices):,} tiles from clusters {cluster_filter}\")\n",
    "        else:\n",
    "            self.valid_indices = None\n",
    "        \n",
    "        self.normalize = normalize\n",
    "        self.band_means = band_means\n",
    "        self.band_stds = band_stds\n",
    "        \n",
    "        n_tiles = len(self.valid_indices) if self.valid_indices is not None else self.features.shape[0]\n",
    "        \n",
    "        print(f\"Loaded Zarr dataset:\")\n",
    "        print(f\"  Features: shape={self.features.shape}, chunks={self.features.chunks}\")\n",
    "        print(f\"  Labels: shape={self.labels.shape}, chunks={self.labels.chunks}\")\n",
    "        print(f\"  Tiles: {n_tiles:,}\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        if self.valid_indices is not None:\n",
    "            return len(self.valid_indices)\n",
    "        return self.features.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Load a single tile by index.\n",
    "        \n",
    "        Zarr will efficiently load from the appropriate chunk.\n",
    "        \"\"\"\n",
    "        # Map to actual index if filtering\n",
    "        if self.valid_indices is not None:\n",
    "            idx = self.valid_indices[idx]\n",
    "        \n",
    "        # Load from Zarr (efficient, uses chunks)\n",
    "        features = torch.from_numpy(np.array(self.features[idx])).float()\n",
    "        labels = torch.from_numpy(np.array(self.labels[idx])).float()\n",
    "        \n",
    "        # Normalize if enabled\n",
    "        if self.normalize and self.band_means is not None:\n",
    "            mean = torch.tensor(self.band_means, dtype=torch.float32).view(-1, 1, 1)\n",
    "            std = torch.tensor(self.band_stds, dtype=torch.float32).view(-1, 1, 1)\n",
    "            features = (features - mean) / (std + 1e-8)\n",
    "        \n",
    "        return features, labels\n",
    "    \n",
    "    def get_tile_metadata(self, idx):\n",
    "        \"\"\"Get metadata for a specific tile.\"\"\"\n",
    "        # Map to actual index if filtering\n",
    "        if self.valid_indices is not None:\n",
    "            idx = self.valid_indices[idx]\n",
    "        \n",
    "        return {\n",
    "            'cluster_id': int(self.zarr_group['cluster_ids'][idx]),\n",
    "            'tile_ix': int(self.zarr_group['tile_ix'][idx]),\n",
    "            'tile_iy': int(self.zarr_group['tile_iy'][idx]),\n",
    "            'year': int(self.zarr_group['years'][idx])\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360503cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Zarr loader\n",
    "zarr_dataset = ZarrMiningDataLoader(zarr_dir)\n",
    "\n",
    "print(f\"\\nDataset length: {len(zarr_dataset)}\")\n",
    "\n",
    "# Load a sample\n",
    "features, labels = zarr_dataset[0]\n",
    "print(f\"\\nSample tile:\")\n",
    "print(f\"  Features: {features.shape}, dtype={features.dtype}\")\n",
    "print(f\"  Labels: {labels.shape}, dtype={labels.dtype}\")\n",
    "print(f\"  Metadata: {zarr_dataset.get_tile_metadata(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95277d6f",
   "metadata": {},
   "source": [
    "## 6. Benchmark: Old vs. Zarr Design\n",
    "\n",
    "We'll benchmark:\n",
    "1. **Single tile access**: Random single tile reads\n",
    "2. **Sequential batch loading**: Loading batches in order\n",
    "3. **Random batch loading**: Loading batches randomly (realistic training)\n",
    "4. **Memory usage**: Peak memory during loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d867bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_single_tile_access(dataset, n_samples=100):\n",
    "    \"\"\"\n",
    "    Benchmark random single tile access.\n",
    "    \"\"\"\n",
    "    indices = np.random.choice(len(dataset), n_samples, replace=False)\n",
    "    \n",
    "    start = time.time()\n",
    "    for idx in indices:\n",
    "        features, labels = dataset[idx]\n",
    "    elapsed = time.time() - start\n",
    "    \n",
    "    return elapsed, elapsed / n_samples\n",
    "\n",
    "\n",
    "def benchmark_batch_loading(dataset, batch_size=32, n_batches=50, shuffle=True, num_workers=0):\n",
    "    \"\"\"\n",
    "    Benchmark batch loading with DataLoader.\n",
    "    \"\"\"\n",
    "    loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=False  # Disable for fair comparison\n",
    "    )\n",
    "    \n",
    "    start = time.time()\n",
    "    for i, (features, labels) in enumerate(loader):\n",
    "        if i >= n_batches:\n",
    "            break\n",
    "        # Simulate some processing\n",
    "        _ = features.shape\n",
    "    elapsed = time.time() - start\n",
    "    \n",
    "    samples_loaded = min(n_batches * batch_size, len(dataset))\n",
    "    return elapsed, samples_loaded / elapsed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be24859",
   "metadata": {},
   "source": [
    "### 6.1 Initialize Both Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86afedfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Old design (memory-mapped .npy)\n",
    "print(\"Initializing old dataset (mmap .npy)...\")\n",
    "old_dataset = MiningSegmentationDataLoader(\n",
    "    normalize=False,  # Disable for fair comparison\n",
    "    auto_compute_stats=False\n",
    ")\n",
    "\n",
    "print(f\"\\nOld dataset: {len(old_dataset)} tiles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22ecddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New design (Zarr)\n",
    "print(\"Initializing new dataset (Zarr)...\")\n",
    "new_dataset = ZarrMiningDataLoader(\n",
    "    zarr_dir=zarr_dir,\n",
    "    normalize=False\n",
    ")\n",
    "\n",
    "print(f\"\\nNew dataset: {len(new_dataset)} tiles\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8771d27",
   "metadata": {},
   "source": [
    "### 6.2 Benchmark Single Tile Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e64fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"BENCHMARK 1: Single Tile Random Access\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "n_samples = 100\n",
    "\n",
    "# Warmup\n",
    "_ = old_dataset[0]\n",
    "_ = new_dataset[0]\n",
    "\n",
    "# Old design\n",
    "print(f\"\\nTesting old design ({n_samples} random tiles)...\")\n",
    "old_total, old_per_tile = benchmark_single_tile_access(old_dataset, n_samples)\n",
    "print(f\"  Total time: {old_total:.3f}s\")\n",
    "print(f\"  Per tile: {old_per_tile*1000:.2f}ms\")\n",
    "\n",
    "# New design\n",
    "print(f\"\\nTesting new design ({n_samples} random tiles)...\")\n",
    "new_total, new_per_tile = benchmark_single_tile_access(new_dataset, n_samples)\n",
    "print(f\"  Total time: {new_total:.3f}s\")\n",
    "print(f\"  Per tile: {new_per_tile*1000:.2f}ms\")\n",
    "\n",
    "# Comparison\n",
    "speedup = old_per_tile / new_per_tile\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Speedup: {speedup:.2f}x {'(Zarr faster)' if speedup > 1 else '(mmap faster)'}\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8c1ba9",
   "metadata": {},
   "source": [
    "### 6.3 Benchmark Sequential Batch Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3960532f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"BENCHMARK 2: Sequential Batch Loading (shuffle=False)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "batch_size = 32\n",
    "n_batches = 50\n",
    "\n",
    "# Old design\n",
    "print(f\"\\nTesting old design (batch_size={batch_size}, {n_batches} batches)...\")\n",
    "old_time, old_throughput = benchmark_batch_loading(old_dataset, batch_size, n_batches, shuffle=False)\n",
    "print(f\"  Total time: {old_time:.3f}s\")\n",
    "print(f\"  Throughput: {old_throughput:.1f} tiles/s\")\n",
    "\n",
    "# New design\n",
    "print(f\"\\nTesting new design (batch_size={batch_size}, {n_batches} batches)...\")\n",
    "new_time, new_throughput = benchmark_batch_loading(new_dataset, batch_size, n_batches, shuffle=False)\n",
    "print(f\"  Total time: {new_time:.3f}s\")\n",
    "print(f\"  Throughput: {new_throughput:.1f} tiles/s\")\n",
    "\n",
    "# Comparison\n",
    "speedup = new_throughput / old_throughput\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Speedup: {speedup:.2f}x {'(Zarr faster)' if speedup > 1 else '(mmap faster)'}\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5688a363",
   "metadata": {},
   "source": [
    "### 6.4 Benchmark Random Batch Loading (Training Scenario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d92fcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"BENCHMARK 3: Random Batch Loading (shuffle=True, realistic training)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "batch_size = 32\n",
    "n_batches = 50\n",
    "\n",
    "# Old design\n",
    "print(f\"\\nTesting old design (batch_size={batch_size}, {n_batches} batches)...\")\n",
    "old_time, old_throughput = benchmark_batch_loading(old_dataset, batch_size, n_batches, shuffle=True)\n",
    "print(f\"  Total time: {old_time:.3f}s\")\n",
    "print(f\"  Throughput: {old_throughput:.1f} tiles/s\")\n",
    "\n",
    "# New design\n",
    "print(f\"\\nTesting new design (batch_size={batch_size}, {n_batches} batches)...\")\n",
    "new_time, new_throughput = benchmark_batch_loading(new_dataset, batch_size, n_batches, shuffle=True)\n",
    "print(f\"  Total time: {new_time:.3f}s\")\n",
    "print(f\"  Throughput: {new_throughput:.1f} tiles/s\")\n",
    "\n",
    "# Comparison\n",
    "speedup = new_throughput / old_throughput\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Speedup: {speedup:.2f}x {'(Zarr faster)' if speedup > 1 else '(mmap faster)'}\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e047d69",
   "metadata": {},
   "source": [
    "### 6.5 Comprehensive Benchmark Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4f0d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run comprehensive benchmarks with multiple configurations\n",
    "print(\"Running comprehensive benchmarks...\\n\")\n",
    "\n",
    "results = []\n",
    "\n",
    "# Test different batch sizes\n",
    "for batch_size in [8, 16, 32, 64]:\n",
    "    print(f\"Testing batch_size={batch_size}...\")\n",
    "    \n",
    "    # Old design\n",
    "    old_time, old_throughput = benchmark_batch_loading(old_dataset, batch_size, 30, shuffle=True)\n",
    "    \n",
    "    # New design\n",
    "    new_time, new_throughput = benchmark_batch_loading(new_dataset, batch_size, 30, shuffle=True)\n",
    "    \n",
    "    results.append({\n",
    "        'batch_size': batch_size,\n",
    "        'old_throughput': old_throughput,\n",
    "        'new_throughput': new_throughput,\n",
    "        'speedup': new_throughput / old_throughput\n",
    "    })\n",
    "\n",
    "# Create results dataframe\n",
    "df_results = pd.DataFrame(results)\n",
    "print(\"\\nResults:\")\n",
    "print(df_results.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f8612d",
   "metadata": {},
   "source": [
    "## 7. Visualize Benchmark Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af518b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot throughput comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Throughput comparison\n",
    "x = df_results['batch_size']\n",
    "width = 0.35\n",
    "x_pos = np.arange(len(x))\n",
    "\n",
    "axes[0].bar(x_pos - width/2, df_results['old_throughput'], width, label='Old (mmap .npy)', alpha=0.8)\n",
    "axes[0].bar(x_pos + width/2, df_results['new_throughput'], width, label='New (Zarr)', alpha=0.8)\n",
    "axes[0].set_xlabel('Batch Size')\n",
    "axes[0].set_ylabel('Throughput (tiles/s)')\n",
    "axes[0].set_title('Data Loading Throughput Comparison')\n",
    "axes[0].set_xticks(x_pos)\n",
    "axes[0].set_xticklabels(x)\n",
    "axes[0].legend()\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Speedup\n",
    "axes[1].plot(df_results['batch_size'], df_results['speedup'], marker='o', linewidth=2, markersize=8)\n",
    "axes[1].axhline(y=1.0, color='r', linestyle='--', alpha=0.5, label='No speedup')\n",
    "axes[1].set_xlabel('Batch Size')\n",
    "axes[1].set_ylabel('Speedup (Zarr / mmap)')\n",
    "axes[1].set_title('Zarr Speedup vs Batch Size')\n",
    "axes[1].grid(alpha=0.3)\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('benchmark_results.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Saved plot: benchmark_results.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f06dacc",
   "metadata": {},
   "source": [
    "## 8. Summary and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be493ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"BENCHMARK SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "avg_speedup = df_results['speedup'].mean()\n",
    "best_speedup = df_results['speedup'].max()\n",
    "worst_speedup = df_results['speedup'].min()\n",
    "\n",
    "print(f\"\\nAverage speedup: {avg_speedup:.2f}x\")\n",
    "print(f\"Best speedup: {best_speedup:.2f}x (batch_size={df_results.loc[df_results['speedup'].idxmax(), 'batch_size']})\")\n",
    "print(f\"Worst speedup: {worst_speedup:.2f}x (batch_size={df_results.loc[df_results['speedup'].idxmin(), 'batch_size']})\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"KEY FINDINGS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "if avg_speedup > 1.1:\n",
    "    print(\"\\n✓ Zarr format provides SIGNIFICANT performance improvement\")\n",
    "    print(\"  Recommendation: MIGRATE to Zarr for production use\")\n",
    "elif avg_speedup > 0.9:\n",
    "    print(\"\\n≈ Zarr and mmap .npy have SIMILAR performance\")\n",
    "    print(\"  Recommendation: Consider other factors (storage, scalability)\")\n",
    "else:\n",
    "    print(\"\\n✗ Zarr format is SLOWER than current mmap approach\")\n",
    "    print(\"  Recommendation: Keep current mmap .npy design\")\n",
    "\n",
    "print(\"\\nAdditional Benefits of Zarr:\")\n",
    "print(\"  • Better chunking for batch operations\")\n",
    "print(\"  • Single file per array (easier management)\")\n",
    "print(\"  • Optional compression for storage savings\")\n",
    "print(\"  • Cloud-native storage support (S3, GCS)\")\n",
    "print(\"  • Parallel write capabilities\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c953fdf",
   "metadata": {},
   "source": [
    "## 9. Optional: Test Different Chunk Sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23679fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This section can be used to experiment with different chunk sizes\n",
    "# Uncomment and run to test chunk_size = 4, 8, 16, 32\n",
    "\n",
    "# chunk_results = []\n",
    "# for chunk_size in [4, 8, 16, 32]:\n",
    "#     print(f\"\\nTesting chunk_size={chunk_size}...\")\n",
    "#     \n",
    "#     # Convert with this chunk size\n",
    "#     test_zarr_dir = config.DATA_DIR / f\"landsat_zarr_chunk{chunk_size}\"\n",
    "#     convert_to_zarr(\n",
    "#         manifests_dir=manifests_dir,\n",
    "#         mmap_dir=mmap_dir,\n",
    "#         zarr_dir=test_zarr_dir,\n",
    "#         chunk_size=chunk_size,\n",
    "#         max_tiles=500\n",
    "#     )\n",
    "#     \n",
    "#     # Benchmark\n",
    "#     test_dataset = ZarrMiningDataLoader(test_zarr_dir, normalize=False)\n",
    "#     elapsed, throughput = benchmark_batch_loading(test_dataset, 32, 30, shuffle=True)\n",
    "#     \n",
    "#     chunk_results.append({\n",
    "#         'chunk_size': chunk_size,\n",
    "#         'throughput': throughput\n",
    "#     })\n",
    "# \n",
    "# df_chunks = pd.DataFrame(chunk_results)\n",
    "# print(\"\\nChunk size analysis:\")\n",
    "# print(df_chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57798db1",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrates:\n",
    "1. ✓ Conversion from mmap .npy tiles to Zarr format\n",
    "2. ✓ Implementation of Zarr-based PyTorch DataLoader\n",
    "3. ✓ Comprehensive benchmarks comparing both approaches\n",
    "4. ✓ Performance analysis across different batch sizes\n",
    "\n",
    "**Next Steps:**\n",
    "- Run full conversion if Zarr shows better performance\n",
    "- Update training scripts to use ZarrMiningDataLoader\n",
    "- Consider cloud storage backends (S3, GCS) for distributed training\n",
    "- Experiment with compression codecs if storage is a concern"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mn)",
   "language": "python",
   "name": "mn"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
